---
title: "DataQueueAnalysis"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a
finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that
includes both content and the output of embedded code. You can embed
code like this:

```{r, echo=FALSE, output=FALSE}
library(stats4)
#install.packages("lubridate")
library(RSQLite)
library(ssh)
library(tidyverse)
library(lubridate)

```

```{r, echo=FALSE, output=FALSE}}
##session
databaseServerIP = "20.13.124.83"
keyFile = "C:/Users/AndreMota/Downloads/DataBaseServerWE_key.pem"
hostDatabaseServer = "sqluser@20.13.124.83:/opt/sqlite3/output.csv"

```

Connect to the consumer server to access the data in the database

```{r}

# Define the source and destination paths
source_path <- hostDatabaseServer
destination_path <- "C:/AppliedDataScienceAndStatistics/Applied-Data-Science-and-Statistics/Term3/heartData/"

# Execute the scp command
command <- paste("scp -i", keyFile, source_path, destination_path)
system(command)



```
Open the file

```{r}

# Connect to the database
heartData <- dbConnect(SQLite(), dbname = "heartData/heart.db")


# Fetch data, casting timestamps as TEXT preserving precision
heartResult <- dbGetQuery(heartData, 
"SELECT id, heart_rate, chest_volume, blood_oxygen_concentration, 
CAST(producer_entry_timestamp AS TEXT) AS producer_entry_timestamp,
CAST(producer_sent_timestamp AS TEXT) AS producer_sent_timestamp,
CAST(kafka_entry_timestamp AS TEXT) AS kafka_entry_timestamp,
CAST(consumer_received_timestamp AS TEXT) AS consumer_received_timestamp,
CAST(consumer_finished_timestamp AS TEXT) AS consumer_finished_timestamp
FROM heart_messages")

# Convert timestamp columns to numeric and to milliseconds
heartResult$producer_entry_timestamp <- as.numeric(heartResult$producer_entry_timestamp) * 1000
heartResult$producer_sent_timestamp <- as.numeric(heartResult$producer_sent_timestamp) * 1000
heartResult$kafka_entry_timestamp <- as.numeric(heartResult$kafka_entry_timestamp) 
heartResult$consumer_received_timestamp <- as.numeric(heartResult$consumer_received_timestamp) * 1000
heartResult$consumer_finished_timestamp <- as.numeric(heartResult$consumer_finished_timestamp) * 1000


# Print full values to check for correct conversion
options(digits = 20) # Increase number of significant digits
print(head(heartResult$producer_entry_timestamp))


# Disconnect from the database
dbDisconnect(heartData)


```


Timestamps wrangling 

```{r}


## calculate execution time 
heartResult$producer_execution_time <- heartResult$producer_sent_timestamp - heartResult$producer_entry_timestamp
heartResult$consumer_execution_time <- heartResult$consumer_finished_timestamp - heartResult$consumer_received_timestamp

## calculate travel time 

heartResult$producer_travel_time <- heartResult$kafka_entry_timestamp - heartResult$producer_sent_timestamp


heartResult$producer_execution_time 
heartResult$consumer_execution_time

heartResult$producer_travel_time

heartResult$queue_service_time = 
  heartResult$consumer_finished_timestamp - heartResult$producer_entry_timestamp

```


```{r}

## use the broker travel times to calculate broker execution

brokerTravelTime = read.csv("heartData/averageTime.csv", header = FALSE, colClasses = c("character"))
colnames(brokerTravelTime) = "kafka_travel_time"

brokerTravelTime$kafka_travel_time = as.numeric(brokerTravelTime$kafka_travel_time) 

brokerTravelTime$kafka_travel_time = brokerTravelTime$kafka_travel_time /1000

heartResult <- cbind(heartResult, brokerTravelTime)


heartResult$kafka_execution_time = heartResult$consumer_received_timestamp - heartResult$kafka_entry_timestamp - heartResult$kafka_travel_time

```



Calculate average arrival rate and service time

```{r}

inter_arrival_times = diff(heartResult$producer_entry_timestamp) 

arrival_rate_lambda <- 1/mean(inter_arrival_times)

service_time_mu = 1 / mean(heartResult$queue_service_time)

traffic_intensity_rho = arrival_rate_lambda / service_time_mu


```
A function for the log-likelihood

```{r}

arrival = nrow(heartResult)

log_likelihood <- function(traffic_intensity_rho, arrival) {
  n <- length(x)
  return(-n*rho + sum(x)*log(rho) - sum(log(factorial(x))))
}


# epsilon <- 0.0001
# result <- optim(par=0.5, fn=log_likelihood, x=x, method="L-BFGS-B", lower=0, upper=1-epsilon)
# rho_hat <- result$par
# 
# if (rho_hat > 1-epsilon) {
#   rho_hat <- 1-epsilon
# }


```


    Use the optim() function in R to find the value of rho that maximizes the log-likelihood. The optim() function performs a one-dimensional optimization of scalar function by iteratively choosing input values within the constraints of the problem. In this case, rho must be between 0 and 1-epsilon, where epsilon is a small positive number close to 0 (e.g., 0.0001).

epsilon <- 0.0001
result <- optim(par=0.5, fn=log_likelihood, x=x, method="L-BFGS-B", lower=0, upper=1-epsilon)
rho_hat <- result$par

    Finally, if the estimated rho is greater than 1-epsilon, set rho to be 1-epsilon.

if (rho_hat > 1-epsilon) {
  rho_hat <- 1-epsilon
}

    The final value of rho_hat is the MLE of rho.


```{r}



```


```{r}



```


```{r}



```


```{r}



```


```{r}



```


```{r}



```


```{r}



```

